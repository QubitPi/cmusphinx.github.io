---
layout: page
title: CMUSphinx Tutorial For Developers
---

## Introduction

This tutorial is going to describe some applications of the CMUSphinx
toolkit.  Such applications could include voice control of mobile,
desktop or automotive applications, language learning, speech
transcription, closed captioning, speech translation, or voice search.
While all of these applications are possible with CMUSphinx, modern
toolkits such as [Kaldi](https://kaldi-asr.org/),
[Coqui](https://coqui.ai/),
[NeMo](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/intro.html),
[Wav2vec2](https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/),
[Whisper](https://github.com/openai/whisper) and
[whisper.cpp](https://github.com/ggerganov/whisper.cpp), etc, etc,
will perform much, much better on larger vocabulary tasks.

The tutorial is intended for developers who need to apply speech
technology in their applications, not for speech recognition researchers.
If you are a researcher, itâ€™s recommended to start with a textbook on speech
technologies. [Spoken Language Processing by Acero, Huang and
others](http://www.amazon.com/Spoken-Language-Processing-Algorithm-Development/d
p/0130226165 ) is a good choice for that.


The structure of this tutorial is the following:

*  [Basic concepts of speech recognition](/wiki/tutorialconcepts)
*  [Overview of the CMUSphinx toolkit](/wiki/tutorialoverview)
*  [Before you start](/wiki/tutorialbeforestart)
*  [Building an application with sphinx4](/wiki/tutorialsphinx4)
*  [Building an application with pocketsphinx](/wiki/tutorialpocketsphinx)
*  [Using PocketSphinx on Android](/wiki/tutorialandroid)
*  [Building a dictionary](/wiki/tutorialdict)
*  [Building a language model](/wiki/tutoriallm)
*  [Adapting an existing acoustic model](/wiki/tutorialadapt)
*  [Training an acoustic model](/wiki/tutorialam)
*  [Tuning the performance](/wiki/tutorialtuning)
